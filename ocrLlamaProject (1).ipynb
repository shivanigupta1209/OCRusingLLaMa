{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr"
      ],
      "metadata": {
        "id": "JTNumeLxQB7l",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPy-SWejKMnR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow opencv-python"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EjKSt8e1ZdpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install torch\n",
        "!pip install huggingface_hub\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZcpOfTDlL_Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T03XD33uZldT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "# Clearing the environment variables\n",
        "if \"HF_TOKEN\" in os.environ:\n",
        "    del os.environ[\"HF_TOKEN\"]\n",
        "\n",
        "if \"HUGGING_FACE_HUB_TOKEN\" in os.environ:\n",
        "    del os.environ[\"HUGGING_FACE_HUB_TOKEN\"]\n",
        "!huggingface-cli logout\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8LvynOgjOq9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "#os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
        "!huggingface-cli login\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A_FrED5YM9bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from huggingface_hub import login\n",
        "#login(\"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\",add_to_git_credential=True)\n",
        "#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\n",
        "login(token=\"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\",add_to_git_credential=True)\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XP0VyXSboNu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WTWMysu9CUf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "import torch, os\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,  #enables 4-bit quantization\n",
        "    bnb_4bit_use_double_quant=True, #for nested quantization where the quantization constants from the first quantization are quantized again.\n",
        "    bnb_4bit_quant_type=\"nf4\",  #ets the quantization data type in the bnb.nn.Linear4Bit layers\n",
        "    bnb_4bit_compute_dtype=torch.float16  #defaults to torch.float32, set to float16 for speedup\n",
        ")\n",
        "cache_dir = '/content/cache_dir'\n",
        "os.makedirs(cache_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "YNUHs8IGQHu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U bitsandbytes\n",
        "from transformers import pipeline, AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
        "#from transformers import load_checkpoint_and_dispatch\n",
        "from huggingface_hub import file_download\n",
        "import accelerate\n",
        "from accelerate import init_empty_weights, infer_auto_device_map\n",
        "#os.environ[\"HF_TOKEN\"] = \"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\" - read only token\n",
        "#os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "config_file = file_download.hf_hub_download(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    filename=\"config.json\"\n",
        "    #use_auth_token=\"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\"  # Explicitly provide the token\n",
        ")\n",
        "config = AutoConfig.from_pretrained(config_file)\n",
        "\n",
        "with init_empty_weights():\n",
        "    model = AutoModelForCausalLM.from_config(config)\n",
        "\n",
        "# Infer device map\n",
        "device_map = infer_auto_device_map(model)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    cache_dir=cache_dir\n",
        ")\n",
        "\n",
        "# Load the model with the quantization configuration\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    config=config,\n",
        "    cache_dir=cache_dir,\n",
        "    #device_map=device_map,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "'''\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer = tokenizer,\n",
        "                config=config,\n",
        "                use_auth_token=True)#cannot pass this during generation\n",
        "pipe(messages)\n",
        "'''"
      ],
      "metadata": {
        "id": "pdqBHZ1n8ZAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import cv2\n",
        "import re"
      ],
      "metadata": {
        "id": "Xj50w_HoK4P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pytesseract.get_tesseract_version)"
      ],
      "metadata": {
        "id": "-ioFFO6_QLCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "mksSM-z1LEqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/X51005230616.jpg\""
      ],
      "metadata": {
        "id": "-HYA2BEKdXsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://www.dropbox.com/scl/fo/pwwpcd1whratlqz7t5r02/AEpnuUxdwn4TcWu-JzdvBwo"
      ],
      "metadata": {
        "id": "VPVEZgDxMp7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image using OpenCV\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform thresholding to create a binary image\n",
        "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "def deskew(image):\n",
        "  #findNoneZero: returns the location of pixels i (x,y) format\n",
        "  #minAreaReact : returns an enclosing rectangle'area that covers all the pts returned by findNonZero\n",
        "  #Returns a tuple containing the center (x, y), size (width, height), and rotation angle of the rectangle.\n",
        "  #cv2.getRotationMatrix2D to rotate the image by the calculated angle around its center.\n",
        "  coords = cv2.findNonZero(cv2.bitwise_not(image))\n",
        "  angle = cv2.minAreaRect(coords)[-1]\n",
        "  if angle <-45:\n",
        "    angle = -(90 + angle)\n",
        "  else:\n",
        "    angle = -angle\n",
        "  (h,w) = image.shape\n",
        "  center = (w//2, h//2)\n",
        "  M = cv2.getRotationMatrix2D(center,angle,1.0)\n",
        "  rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "  return rotated\n",
        "\n",
        "gray = deskew(cv2.medianBlur(thresh, 5))\n",
        "img = Image.fromarray(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "Bmq8ds-GeSaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = pytesseract.image_to_string(thresh, config = r'--oem 3 --psm 6')\n",
        "print(text)\n",
        "#oem = ocr engine machine & psm = page segmentation mode"
      ],
      "metadata": {
        "id": "BMSsngL5MW7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "1o95jbvJLJdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "wGeonWqVS-O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxqJEK_rc1P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "\n",
        "TASK:\n",
        "Extract the following fromtext based on the instruction provided below and display in same format:\n",
        "\n",
        "\\n''' +text+ '''\\n\n",
        "\n",
        "{\n",
        "  \"issuing_institution\": extract name of issuing institution from text\n",
        "  \"issuing_institution_address\": extract address of issuing institution from text\n",
        "  \"gst_id\": extract GST ID from text\n",
        "  \"phone_number\": extract phone number from text. If multiple numbers are present, create a list containing them as strings.\n",
        "  \"items\": {\n",
        "      \"Item1 Name\": [Quantity, Size, Price]\n",
        "      \"Item2 Name\": [Quantity, Size, Price]\n",
        "      and so on till all items in text are convered\n",
        "  }\n",
        "  - a dictionary that contains sub-keys that are the name of a particular item. Value will be a list storing [quantity, size of item, cost of that particular item] which are extracted from text.\n",
        "  - Size of item ordered would be S, M, or L categorizing small, medium, and large. It may also be some measurement in numerical form.\n",
        "  - Quantity and size may be connected together in text, separate them accordingly.\n",
        "  - Item ordered and size of item should be in string format\n",
        "  - Quantity of item should be returned as a number\n",
        "  - For items that have no cost, return \"NA\"\n",
        "  \"total_price\": extract total price of the order from text\n",
        "  \"customer_service_number\": extract customer service number from text\n",
        "}\n",
        "For any information not found, return \"NA\"\n",
        "Give no explanation\n",
        "'''"
      ],
      "metadata": {
        "id": "WGHnEUzihzs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer = tokenizer,\n",
        "                config=config)"
      ],
      "metadata": {
        "id": "CmClGyQH5bC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text = pipe(prompt,max_new_tokens=500, num_return_sequences=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IEZSTE6bTqUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6Y6UE07SfiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = extracted_text[0]['generated_text'].replace(prompt, \"\").strip()\n",
        "\n",
        "# Print or use the generated text\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "-hhKZEuOUEnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomJSONEncoder(json.JSONEncoder):\n",
        "    def encode(self, obj):\n",
        "        if isinstance(obj, list):\n",
        "            # Join the list elements with ', ' to ensure they are on the same line\n",
        "            return '[' + ', '.join(self.encode(e) for e in obj) + ']'\n",
        "        if isinstance(obj, dict):\n",
        "            items = []\n",
        "            for k, v in obj.items():\n",
        "                items.append(f'{json.dumps(k)}: {self.encode(v)}')\n",
        "            # Join the dictionary items with proper indentation\n",
        "            return '{' + ', '.join(items) + '}'\n",
        "        return json.dumps(obj)"
      ],
      "metadata": {
        "id": "NiVX7B9KesZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_json = {\n",
        "    \"image_path\": img_path,\n",
        "    \"extracted_key_value_pairs\": json.loads(generated_text)\n",
        "}\n",
        "\n",
        "# Convert Python dictionary to JSON string\n",
        "json_str = json.dumps(output_json, indent=4, cls = CustomJSONEncoder)\n",
        "\n",
        "# Print the JSON string\n",
        "print(json_str)"
      ],
      "metadata": {
        "id": "z_-wBdKHT6Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_json['extracted_key_value_pairs']"
      ],
      "metadata": {
        "id": "Oiw40fWfW04c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "lJPwIpqD2vJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}